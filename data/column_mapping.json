{
    "P0": "id",
    "P1_a": "Idade",
    "P1_a_1": "Faixa idade",
    "P1_b": "Genero",
    "P1_c": "Cor/raca/etnia",
    "P1_d": "PCD",
    "P1_e": "experiencia_profissional_prejudicada",
    "P1_f": "aspectos_prejudicados",
    "P1_g": "vive_no_brasil",
    "P1_i": "Estado onde mora",
    "P1_i_1": "uf onde mora",
    "P1_i_2": "Regiao onde mora",
    "P1_j": "Mudou de Estado?",
    "P1_k": "Regiao de origem",
    "P1_l": "Nivel de Ensino",
    "P1_m": "Área de Formação",
    "P2_a": "Qual sua situação atual de trabalho?",
    "P2_b": "Setor",
    "P2_c": "Numero de Funcionarios",
    "P2_d": "Gestor?",
    "P2_e": "Cargo como Gestor",
    "P2_f": "Cargo Atual",
    "P2_g": "Nivel",
    "P2_h": "Faixa salarial",
    "P2_i": "Quanto tempo de experiência na área de dados você tem?",
    "P2_j": "Quanto tempo de experiência na área de TI/Engenharia de Software você teve antes de começar a trabalhar na área de dados?",
    "P2_k": "Você está satisfeito na sua empresa atual?",
    "P2_l": "Qual o principal motivo da sua insatisfação com a empresa atual?",
    "P2_l_1": "Falta de oportunidade de crescimento no emprego atual",
    "P2_l_2": "Salário atual não corresponde ao mercado",
    "P2_l_3": "Não tenho uma boa relação com meu líder/gestor",
    "P2_l_4": "Gostaria de trabalhar em em outra área de atuação",
    "P2_l_5": "Gostaria de receber mais benefícios",
    "P2_l_6": "O clima de trabalho/ambiente não é bom",
    "P2_l_7": "Falta de maturidade analítica na empresa",
    "P2_m": "Você participou de entrevistas de emprego nos últimos 6 meses?",
    "P2_n": "Você pretende mudar de emprego nos próximos 6 meses?",
    "P2_o": "Quais os principais critérios que você leva em consideração no momento de decidir onde trabalhar?",
    "P2_o_1": "Remuneração/Salário",
    "P2_o_10": "Reputação que a empresa tem no mercado",
    "P2_o_2": "Benefícios",
    "P2_o_3": "Propósito do trabalho e da empresa",
    "P2_o_4": "Flexibilidade de trabalho remoto",
    "P2_o_5": "Ambiente e clima de trabalho",
    "P2_o_6": "Oportunidade de aprendizado e trabalhar com referências na área",
    "P2_o_7": "Plano de carreira e oportunidades de crescimento profissional",
    "P2_o_8": "Maturidade da empresa em termos de tecnologia e dados",
    "P2_o_9": "Qualidade dos gestores e líderes",
    "P2_p": "Atualmente qual a sua forma de trabalho?",
    "P2_q": "Qual a forma de trabalho ideal para você?",
    "P2_r": "Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?",
    "P2_s": "Sua empresa passu por Layoff em 2022?",
    "P3_a": "Qual o número aproximado de pessoas que atuam com dados na sua empresa hoje?",
    "P3_b": "Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?",
    "P3_b_1": "Analytics Engineer",
    "P3_b_2": "Engenharia de Dados/Data Engineer",
    "P3_b_3": "Analista de Dados/Data Analyst",
    "P3_b_4": "Cientista de Dados/Data Scientist",
    "P3_b_5": "Database Administrator/DBA",
    "P3_b_6": "Analista de Business Intelligence/BI",
    "P3_b_7": "Arquiteto de Dados/Data Architect",
    "P3_b_8": "Data Product Manager/DPM",
    "P3_b_9": "Business Analyst",
    "P3_c": "Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?",
    "P3_c_1": "Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.",
    "P3_c_10": "Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.",
    "P3_c_11": "Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira",
    "P3_c_2": "Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.",
    "P3_c_3": "Atração, seleção e contratação de talentos para o time de dados.",
    "P3_c_4": "Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.",
    "P3_c_5": "Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.",
    "P3_c_6": "Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.",
    "P3_c_7": "Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.",
    "P3_c_8": "Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.",
    "P3_c_9": "Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.",
    "P3_d": "Quais são os 3 maiores desafios que você tem como gestor no atual momento?",
    "P3_d_1": "a Contratar novos talentos.",
    "P3_d_10": "j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.",
    "P3_d_11": "k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.",
    "P3_d_12": "Conseguir levar inovação para a empresa através dos dados.",
    "P3_d_13": "Garantir retorno do investimento (ROI) em projetos de dados.",
    "P3_d_14": "Dividir o tempo entre entregas técnicas e gestão.",
    "P3_d_2": "b Reter talentos.",
    "P3_d_3": "c Convencer a empresa a aumentar os investimentos na área de dados.",
    "P3_d_4": "d Gestão de equipes no ambiente remoto.",
    "P3_d_5": "e Gestão de projetos envolvendo áreas multidisciplinares da empresa.",
    "P3_d_6": "f Organizar as informações e garantir a qualidade e confiabilidade.",
    "P3_d_7": "g Conseguir processar e armazenar um alto volume de dados.",
    "P3_d_8": "h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.",
    "P3_d_9": "i Desenvolver e manter modelos Machine Learning em produção.",
    "P4_a": "Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?",
    "P4_a_1": "Atuacao",
    "P4_b": "Quais das fontes de dados listadas você já analisou ou processou no trabalho?",
    "P4_b_1": "Dados relacionais (estruturados em bancos SQL",
    "P4_b_2": "Dados armazenados em bancos NoSQL",
    "P4_b_3": "Imagens",
    "P4_b_4": "Textos/Documentos",
    "P4_b_5": "Vídeos",
    "P4_b_6": "Áudios",
    "P4_b_7": "Planilhas",
    "P4_b_8": "Dados georeferenciados",
    "P4_c": "Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?",
    "P4_c_1": "Dados relacionais (estruturados em bancos SQL",
    "P4_c_2": "Dados armazenados em bancos NoSQL",
    "P4_c_3": "Imagens",
    "P4_c_4": "Textos/Documentos",
    "P4_c_5": "Vídeos",
    "P4_c_6": "Áudios",
    "P4_c_7": "Planilhas",
    "P4_c_8": "Dados georeferenciados",
    "P4_d": "Quais das linguagens listadas abaixo você utiliza no trabalho?",
    "P4_d_1": "SQL",
    "P4_d_10": "Scala",
    "P4_d_11": "Matlab",
    "P4_d_12": "PHP",
    "P4_d_13": "Javascript",
    "P4_d_14": "Não utilizo nenhuma linguagem",
    "P4_d_2": "R ",
    "P4_d_3": "Python",
    "P4_d_4": "C/C++/C#",
    "P4_d_5": ".NET",
    "P4_d_6": "Java",
    "P4_d_7": "Julia",
    "P4_d_8": "SAS/Stata",
    "P4_d_9": "Visual Basic/VBA",
    "P4_e": "Entre as linguagens listadas abaixo, qual é a que você mais utiliza no trabalho?",
    "P4_f": "Entre as linguagens listadas abaixo, qual é a sua preferida?",
    "P4_f_10": "Datomic",
    "P4_f_11": "S3",
    "P4_f_12": "PostgreSQL",
    "P4_f_13": "ElasticSearch",
    "P4_f_14": "DB2",
    "P4_f_15": "Microsoft Access",
    "P4_f_16": "SQLite",
    "P4_f_17": "Sybase",
    "P4_f_18": "Firebase",
    "P4_f_19": "Vertica",
    "P4_f_20": "Redis",
    "P4_f_21": "Neo4J",
    "P4_f_22": "Google BigQuery",
    "P4_f_23": "Google Firestore",
    "P4_f_24": "Amazon Redshift",
    "P4_f_25": "Amazon Athena",
    "P4_f_26": "Snowflake",
    "P4_f_27": "Databricks",
    "P4_f_28": "HBase",
    "P4_f_29": "Presto",
    "P4_f_30": "Splunk",
    "P4_f_31": "SAP HANA",
    "P4_f_32": "Hive",
    "P4_f_33": "Firebird",
    "P4_f_4": "Amazon Aurora ou RDS",
    "P4_f_5": "DynamoDB",
    "P4_f_6": "CoachDB",
    "P4_f_7": "Cassandra",
    "P4_f_8": "MongoDB",
    "P4_f_9": "MariaDB",
    "P4_g": "Quais das opções de Cloud listadas abaixo você utiliza no trabalho?",
    "P4_g_1": "MySQL",
    "P4_g_2": "Oracle",
    "P4_g_3": "SQL SERVER",
    "P4_h": "Dentre as opções listadas, qual sua Cloud preferida?",
    "P4_h_1": "Azure (Microsoft",
    "P4_h_2": "Amazon Web Services (AWS",
    "P4_h_3": "Google Cloud (GCP",
    "P4_i": "Microsoft PowerBI",
    "P4_i_1": "Microsoft PowerBI",
    "P4_i_10": "Oracle Business Intelligence",
    "P4_i_11": "Amazon QuickSight",
    "P4_i_12": "Salesforce/Einstein Analytics",
    "P4_i_13": "Mode",
    "P4_i_14": "Alteryx",
    "P4_i_15": "Birst",
    "P4_i_16": "Looker",
    "P4_i_17": "Google Data Studio",
    "P4_i_18": "SAS Visual Analytics",
    "P4_i_19": "Grafana",
    "P4_i_2": "Qlik View/Qlik Sense",
    "P4_i_20": "TIBCO Spotfire",
    "P4_i_21": "Pentaho",
    "P4_i_22": "Fazemos todas as análises utilizando apenas Excel ou planilhas do google",
    "P4_i_23": "Não utilizo nenhuma ferramenta de BI no trabalho",
    "P4_i_3": "Tableau",
    "P4_i_4": "Metabase",
    "P4_i_5": "Superset",
    "P4_i_6": "Redash",
    "P4_i_7": "MicroStrategy",
    "P4_i_8": "IBM Analytics/Cognos",
    "P4_i_9": "SAP Business Objects",
    "P5_a": "Qual seu objetivo na área de dados?",
    "P5_b": "Qual oportunidade você está buscando?",
    "P5_c": "Há quanto tempo você busca uma oportunidade na área de dados?",
    "P5_d": "Como tem sido a busca por um emprego na área de dados?",
    "P6_a": "Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?",
    "P6_a_1": "Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.",
    "P6_a_2": "Realizo construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc.",
    "P6_a_3": "Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.",
    "P6_a_4": "Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.",
    "P6_a_5": "Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.",
    "P6_a_6": "Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.",
    "P6_a_7": "Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.",
    "P6_a_8": "Cuido da qualidade dos dados, metadados e dicionário de dados.",
    "P6_a_9": "Nenhuma das opções listadas refletem meu dia a dia.",
    "P6_b": "Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?",
    "P6_b_1": "Scripts Python",
    "P6_b_10": "Fivetran",
    "P6_b_11": "Google Dataflow",
    "P6_b_12": "Oracle Data Integrator",
    "P6_b_13": "IBM DataStage",
    "P6_b_14": "SAP BW ETL",
    "P6_b_15": "SQL Server Integration Services (SSIS",
    "P6_b_16": "SAS Data Integration",
    "P6_b_17": "Qlik Sense",
    "P6_b_18": "Knime",
    "P6_b_19": "Não utilizo ferramentas de ETL",
    "P6_b_2": "SQL & Stored Procedures",
    "P6_b_3": "Apache Airflow",
    "P6_b_4": "Luigi",
    "P6_b_5": "AWS Glue",
    "P6_b_6": "Talend",
    "P6_b_7": "Pentaho",
    "P6_b_8": "Alteryx",
    "P6_b_9": "Stitch",
    "P6_c": "Sua organização possui um Data Lake?",
    "P6_d": "Qual tecnologia utilizada como plataforma do Data Lake?",
    "P6_e": "Sua organização possui um Data Warehouse?",
    "P6_f": "Qual tecnologia utilizada como plataforma do Data Warehouse?",
    "P6_g": "Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?",
    "P6_g_1": "great_expectations",
    "P6_g_10": "Data Band",
    "P6_g_11": "Anomalo",
    "P6_g_2": "dbt",
    "P6_g_3": "AWS Deequ",
    "P6_g_4": "Apache Griffin",
    "P6_g_5": "Datafold",
    "P6_g_6": "Amundsen",
    "P6_g_7": "Monte Carlo",
    "P6_g_8": "SODA",
    "P6_g_9": "Big Eye",
    "P6_g_l": "Metaplane",
    "P6_g_m": "Acceldata",
    "P6_h": "Em qual das opções abaixo você gasta a maior parte do seu tempo?",
    "P6_h_1": "Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.",
    "P6_h_2": "Realizando construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc.",
    "P6_h_3": "Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.",
    "P6_h_4": "Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.",
    "P6_h_5": "Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.",
    "P6_h_6": "Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.",
    "P6_h_7": "Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.",
    "P6_h_8": "Cuidando da qualidade dos dados, metadados e dicionário de dados.",
    "P6_h_9": "Nenhuma das opções listadas refletem meu dia a dia.",
    "P7_1": "Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?",
    "P7_a_1": "Processo e analiso dados utilizando linguagens de programação como Python, R etc.",
    "P7_a_10": "Nenhuma das opções listadas refletem meu dia a dia.",
    "P7_a_2": "Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.",
    "P7_a_3": "Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.",
    "P7_a_4": "Utilizo APIs para extrair dados e complementar minhas análises.",
    "P7_a_5": "Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.",
    "P7_a_6": "Desenvolvo/cuido da manutenção de ETLs utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.",
    "P7_a_7": "Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.",
    "P7_a_8": "Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.",
    "P7_a_9": "Utilizo ferramentas avançadas de estatística como SAS",
    "P7_b": "Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?",
    "P7_b_1": "Scripts Python",
    "P7_b_10": "Fivetran",
    "P7_b_11": "Google Dataflow",
    "P7_b_12": "Oracle Data Integrator",
    "P7_b_13": "IBM DataStage",
    "P7_b_14": "SAP BW ETL",
    "P7_b_15": "SQL Server Integration Services (SSIS",
    "P7_b_16": "SAS Data Integration",
    "P7_b_17": "Qlik Sense",
    "P7_b_18": "Knime",
    "P7_b_19": "Databricks",
    "P7_b_2": "SQL & Stored Procedures",
    "P7_b_20": "Não utilizo ferramentas de ETL",
    "P7_b_3": "Apache Airflow",
    "P7_b_4": "Luigi",
    "P7_b_5": "AWS Glue",
    "P7_b_6": "Talend",
    "P7_b_7": "Pentaho",
    "P7_b_8": "Alteryx",
    "P7_b_9": "Stitch",
    "P7_c": "Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?",
    "P7_c_1": "Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.",
    "P7_c_2": "\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.",
    "P7_c_3": "Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.",
    "P7_c_4": "Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.",
    "P7_c_5": "Minha empresa não utiliza essas ferramentas.",
    "P7_c_6": "Não sei informar.",
    "P7_d": "Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?",
    "P7_d_1": "Processando e analisando dados utilizando linguagens de programação como Python, R etc.",
    "P7_d_10": "Nenhuma das opções listadas refletem meu dia a dia.",
    "P7_d_2": "Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.",
    "P7_d_3": "Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.",
    "P7_d_4": "Utilizando APIs para extrair dados e complementar minhas análises.",
    "P7_d_5": "Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.",
    "P7_d_6": "Desenvolvendo/cuidando da manutenção de ETLs utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.",
    "P7_d_7": "Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.",
    "P7_d_8": "Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.",
    "P7_d_9": "Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.",
    "P8_3": "Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?",
    "P8_a": "Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?",
    "P8_a_1": "Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.",
    "P8_a_10": "Crio e gerencio soluções de Feature Store e cultura de MLOps.",
    "P8_a_11": "Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.",
    "P8_a_2": "Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.",
    "P8_a_3": "Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.",
    "P8_a_4": "Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).",
    "P8_a_5": "Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.",
    "P8_a_6": "Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.",
    "P8_a_7": "Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc",
    "P8_a_8": "Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.",
    "P8_a_9": "Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.",
    "P8_b": "Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?",
    "P8_b_1": "Utilizo modelos de regressão (linear, logística, GLM",
    "P8_b_10": "Utilizo modelos de Reinforcement Learning (aprendizado por reforço",
    "P8_b_11": "Utilizo modelos de Machine Learning para detecção de fraude",
    "P8_b_2": "Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação",
    "P8_b_3": "Desenvolvo sistemas de recomendação (RecSys",
    "P8_b_4": "Utilizo métodos estatísticos Bayesianos para analisar dados",
    "P8_b_5": "Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados",
    "P8_b_6": "Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados",
    "P8_b_7": "Utilizo cadeias de Markov ou HMMs para realizar análises de dados",
    "P8_b_8": "Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc",
    "P8_b_9": "Realizo previsões através de modelos de Séries Temporais (Time Series",
    "P8_b_l": "Utilizo métodos de Visão Computacional",
    "P8_b_m": "Utilizo modelos de Detecção de Churn",
    "P8_c_1": "Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc",
    "P8_c_10": "Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc",
    "P8_c_11": "Ferramentas de estatística avançada como SPSS, SAS, etc.",
    "P8_c_2": "Planilhas (Excel, Google Sheets etc",
    "P8_c_3": "Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda",
    "P8_c_4": "Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc",
    "P8_c_5": "Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc",
    "P8_c_6": "Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc",
    "P8_c_7": "Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc",
    "P8_c_8": "Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc",
    "P8_c_9": "Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc",
    "P8_d": "Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?",
    "P8_d_1": "Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.",
    "P8_d_10": "Criando e gerenciando soluções de Feature Store e cultura de MLOps.",
    "P8_d_11": "Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.",
    "P8_d_2": "Coletando e limpando os dados que uso para análise e modelagem.",
    "P8_d_3": "Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.",
    "P8_d_4": "Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).",
    "P8_d_5": "Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.",
    "P8_d_6": "Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.",
    "P8_d_7": "Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.",
    "P8_d_8": "Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.",
    "P8_d_9": "Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados."
}