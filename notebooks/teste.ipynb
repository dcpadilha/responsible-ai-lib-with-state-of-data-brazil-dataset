{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo_3y8emb6\\AppData\\Local\\Temp\\ipykernel_15252\\4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../state-of-data-2022/State_of_data_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('P0', 'id')</th>\n",
       "      <th>('P1_a ', 'Idade')</th>\n",
       "      <th>('P1_a_1 ', 'Faixa idade')</th>\n",
       "      <th>('P1_b ', 'Genero')</th>\n",
       "      <th>('P1_c ', 'Cor/raca/etnia')</th>\n",
       "      <th>('P1_d ', 'PCD')</th>\n",
       "      <th>('P1_e ', 'experiencia_profissional_prejudicada')</th>\n",
       "      <th>('P1_f ', 'aspectos_prejudicados')</th>\n",
       "      <th>('P1_g ', 'vive_no_brasil')</th>\n",
       "      <th>('P1_i ', 'Estado onde mora')</th>\n",
       "      <th>...</th>\n",
       "      <th>('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')</th>\n",
       "      <th>('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')</th>\n",
       "      <th>('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')</th>\n",
       "      <th>('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')</th>\n",
       "      <th>('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')</th>\n",
       "      <th>('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')</th>\n",
       "      <th>('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')</th>\n",
       "      <th>('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')</th>\n",
       "      <th>('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')</th>\n",
       "      <th>('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzqzz3l9ily8nuo2m7wyzzqzz3w48o96</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35-39</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não acredito que minha experiência profissiona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Distrito Federal (DF)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzls2oftfn9law393oezzls2ofhvfpzd</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim, acredito que a minha a experiência profis...</td>\n",
       "      <td>Aprovação em processos seletivos/entrevistas</td>\n",
       "      <td>True</td>\n",
       "      <td>Pará (PA)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzdwqzfqqp1ypc7ps6m0hzzdwqz292yi</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Distrito Federal (DF)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzbqh3uy7yk7k9qmkzzbqtb4s9faqspl</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25-29</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Minas Gerais (MG)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzaf1m95yan929rb94wzzaf1mekhvhpg</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45-49</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não acredito que minha experiência profissiona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Pará (PA)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ('P0', 'id')  ('P1_a ', 'Idade')  \\\n",
       "0  zzqzz3l9ily8nuo2m7wyzzqzz3w48o96                39.0   \n",
       "1  zzls2oftfn9law393oezzls2ofhvfpzd                32.0   \n",
       "2  zzdwqzfqqp1ypc7ps6m0hzzdwqz292yi                53.0   \n",
       "3  zzbqh3uy7yk7k9qmkzzbqtb4s9faqspl                27.0   \n",
       "4  zzaf1m95yan929rb94wzzaf1mekhvhpg                46.0   \n",
       "\n",
       "  ('P1_a_1 ', 'Faixa idade') ('P1_b ', 'Genero') ('P1_c ', 'Cor/raca/etnia')  \\\n",
       "0                      35-39           Masculino                       Parda   \n",
       "1                      30-34           Masculino                       Parda   \n",
       "2                      50-54           Masculino                      Branca   \n",
       "3                      25-29           Masculino                      Branca   \n",
       "4                      45-49            Feminino                      Branca   \n",
       "\n",
       "  ('P1_d ', 'PCD')  ('P1_e ', 'experiencia_profissional_prejudicada')  \\\n",
       "0              Não  Não acredito que minha experiência profissiona...   \n",
       "1              Não  Sim, acredito que a minha a experiência profis...   \n",
       "2              Não                                                NaN   \n",
       "3              Não                                                NaN   \n",
       "4              Não  Não acredito que minha experiência profissiona...   \n",
       "\n",
       "             ('P1_f ', 'aspectos_prejudicados')  ('P1_g ', 'vive_no_brasil')  \\\n",
       "0                                           NaN                         True   \n",
       "1  Aprovação em processos seletivos/entrevistas                         True   \n",
       "2                                           NaN                         True   \n",
       "3                                           NaN                         True   \n",
       "4                                           NaN                         True   \n",
       "\n",
       "  ('P1_i ', 'Estado onde mora')  ...  \\\n",
       "0         Distrito Federal (DF)  ...   \n",
       "1                     Pará (PA)  ...   \n",
       "2         Distrito Federal (DF)  ...   \n",
       "3             Minas Gerais (MG)  ...   \n",
       "4                     Pará (PA)  ...   \n",
       "\n",
       "  ('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')  \\\n",
       "0                                                NaN                               \n",
       "1                                                NaN                               \n",
       "2                                                0.0                               \n",
       "3                                                1.0                               \n",
       "4                                                NaN                               \n",
       "\n",
       "  ('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')  \\\n",
       "0                                                NaN                                                                                           \n",
       "1                                                NaN                                                                                           \n",
       "2                                                1.0                                                                                           \n",
       "3                                                0.0                                                                                           \n",
       "4                                                NaN                                                                                           \n",
       "\n",
       "  ('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')  \\\n",
       "0                                                NaN                                                                                \n",
       "1                                                NaN                                                                                \n",
       "2                                                0.0                                                                                \n",
       "3                                                0.0                                                                                \n",
       "4                                                NaN                                                                                \n",
       "\n",
       "  ('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')  \\\n",
       "0                                                NaN                                                              \n",
       "1                                                NaN                                                              \n",
       "2                                                0.0                                                              \n",
       "3                                                0.0                                                              \n",
       "4                                                NaN                                                              \n",
       "\n",
       "  ('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')  \\\n",
       "0                                                NaN                                                                                                        \n",
       "1                                                NaN                                                                                                        \n",
       "2                                                0.0                                                                                                        \n",
       "3                                                0.0                                                                                                        \n",
       "4                                                NaN                                                                                                        \n",
       "\n",
       "  ('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')  \\\n",
       "0                                                NaN                                                                   \n",
       "1                                                NaN                                                                   \n",
       "2                                                0.0                                                                   \n",
       "3                                                0.0                                                                   \n",
       "4                                                NaN                                                                   \n",
       "\n",
       "  ('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')  \\\n",
       "0                                                NaN                                                                  \n",
       "1                                                NaN                                                                  \n",
       "2                                                0.0                                                                  \n",
       "3                                                0.0                                                                  \n",
       "4                                                NaN                                                                  \n",
       "\n",
       "  ('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')  \\\n",
       "0                                                NaN                                            \n",
       "1                                                NaN                                            \n",
       "2                                                0.0                                            \n",
       "3                                                0.0                                            \n",
       "4                                                NaN                                            \n",
       "\n",
       "  ('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')  \\\n",
       "0                                                NaN                                    \n",
       "1                                                NaN                                    \n",
       "2                                                0.0                                    \n",
       "3                                                0.0                                    \n",
       "4                                                NaN                                    \n",
       "\n",
       "  ('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')  \n",
       "0                                                NaN                                                                          \n",
       "1                                                NaN                                                                          \n",
       "2                                                0.0                                                                          \n",
       "3                                                0.0                                                                          \n",
       "4                                                NaN                                                                          \n",
       "\n",
       "[5 rows x 353 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P1_a_1 ', 'Faixa idade')\n",
       "25-29    1398\n",
       "30-34    1095\n",
       "35-39     598\n",
       "22-24     449\n",
       "40-44     277\n",
       "17-21     152\n",
       "45-49     145\n",
       "50-54      89\n",
       "55+        68\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"('P1_a_1 ', 'Faixa idade')\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P1_k ', 'Regiao de origem')\n",
       "NaN             3499\n",
       "Sudeste          356\n",
       "Nordeste         190\n",
       "Sul              121\n",
       "Centro-oeste      58\n",
       "Norte             47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"('P1_k ', 'Regiao de origem')\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    column = column.strip(\"(')\")\n",
    "    column = column.replace(\"'\", \"\").split(', ')\n",
    "\n",
    "    features[column[0].strip()] = ', '.join(column[1:])\n",
    "\n",
    "    #print(column[0])\n",
    "    #print(', '.join(column[1:]))\n",
    "    #print('-----')#features[column[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P0': 'id',\n",
       " 'P1_a': 'Idade',\n",
       " 'P1_a_1': 'Faixa idade',\n",
       " 'P1_b': 'Genero',\n",
       " 'P1_c': 'Cor/raca/etnia',\n",
       " 'P1_d': 'PCD',\n",
       " 'P1_e': 'experiencia_profissional_prejudicada',\n",
       " 'P1_f': 'aspectos_prejudicados',\n",
       " 'P1_g': 'vive_no_brasil',\n",
       " 'P1_i': 'Estado onde mora',\n",
       " 'P1_i_1': 'uf onde mora',\n",
       " 'P1_i_2': 'Regiao onde mora',\n",
       " 'P1_j': 'Mudou de Estado?',\n",
       " 'P1_k': 'Regiao de origem',\n",
       " 'P1_l': 'Nivel de Ensino',\n",
       " 'P1_m': 'Área de Formação',\n",
       " 'P2_a': 'Qual sua situação atual de trabalho?',\n",
       " 'P2_b': 'Setor',\n",
       " 'P2_c': 'Numero de Funcionarios',\n",
       " 'P2_d': 'Gestor?',\n",
       " 'P2_e': 'Cargo como Gestor',\n",
       " 'P2_f': 'Cargo Atual',\n",
       " 'P2_g': 'Nivel',\n",
       " 'P2_h': 'Faixa salarial',\n",
       " 'P2_i': 'Quanto tempo de experiência na área de dados você tem?',\n",
       " 'P2_j': 'Quanto tempo de experiência na área de TI/Engenharia de Software você teve antes de começar a trabalhar na área de dados?',\n",
       " 'P2_k': 'Você está satisfeito na sua empresa atual?',\n",
       " 'P2_l': 'Qual o principal motivo da sua insatisfação com a empresa atual?',\n",
       " 'P2_l_1': 'Falta de oportunidade de crescimento no emprego atual',\n",
       " 'P2_l_2': 'Salário atual não corresponde ao mercado',\n",
       " 'P2_l_3': 'Não tenho uma boa relação com meu líder/gestor',\n",
       " 'P2_l_4': 'Gostaria de trabalhar em em outra área de atuação',\n",
       " 'P2_l_5': 'Gostaria de receber mais benefícios',\n",
       " 'P2_l_6': 'O clima de trabalho/ambiente não é bom',\n",
       " 'P2_l_7': 'Falta de maturidade analítica na empresa',\n",
       " 'P2_m': 'Você participou de entrevistas de emprego nos últimos 6 meses?',\n",
       " 'P2_n': 'Você pretende mudar de emprego nos próximos 6 meses?',\n",
       " 'P2_o': 'Quais os principais critérios que você leva em consideração no momento de decidir onde trabalhar?',\n",
       " 'P2_o_1': 'Remuneração/Salário',\n",
       " 'P2_o_2': 'Benefícios',\n",
       " 'P2_o_3': 'Propósito do trabalho e da empresa',\n",
       " 'P2_o_4': 'Flexibilidade de trabalho remoto',\n",
       " 'P2_o_5': 'Ambiente e clima de trabalho',\n",
       " 'P2_o_6': 'Oportunidade de aprendizado e trabalhar com referências na área',\n",
       " 'P2_o_7': 'Plano de carreira e oportunidades de crescimento profissional',\n",
       " 'P2_o_8': 'Maturidade da empresa em termos de tecnologia e dados',\n",
       " 'P2_o_9': 'Qualidade dos gestores e líderes',\n",
       " 'P2_o_10': 'Reputação que a empresa tem no mercado',\n",
       " 'P2_p': 'Atualmente qual a sua forma de trabalho?',\n",
       " 'P2_q': 'Qual a forma de trabalho ideal para você?',\n",
       " 'P2_r': 'Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?',\n",
       " 'P2_s': 'Sua empresa passu por Layoff em 2022?',\n",
       " 'P3_a': 'Qual o número aproximado de pessoas que atuam com dados na sua empresa hoje?',\n",
       " 'P3_b': 'Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?',\n",
       " 'P3_b_1': 'Analytics Engineer',\n",
       " 'P3_b_2': 'Engenharia de Dados/Data Engineer',\n",
       " 'P3_b_3': 'Analista de Dados/Data Analyst',\n",
       " 'P3_b_4': 'Cientista de Dados/Data Scientist',\n",
       " 'P3_b_5': 'Database Administrator/DBA',\n",
       " 'P3_b_6': 'Analista de Business Intelligence/BI',\n",
       " 'P3_b_7': 'Arquiteto de Dados/Data Architect',\n",
       " 'P3_b_8': 'Data Product Manager/DPM',\n",
       " 'P3_b_9': 'Business Analyst',\n",
       " 'P3_c': 'Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?',\n",
       " 'P3_c_1': 'Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.',\n",
       " 'P3_c_2': 'Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.',\n",
       " 'P3_c_3': 'Atração, seleção e contratação de talentos para o time de dados.',\n",
       " 'P3_c_4': 'Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.',\n",
       " 'P3_c_5': 'Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.',\n",
       " 'P3_c_6': 'Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.',\n",
       " 'P3_c_7': 'Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.',\n",
       " 'P3_c_8': 'Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.',\n",
       " 'P3_c_9': 'Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.',\n",
       " 'P3_c_10': 'Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.',\n",
       " 'P3_c_11': 'Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira',\n",
       " 'P3_d': 'Quais são os 3 maiores desafios que você tem como gestor no atual momento?',\n",
       " 'P3_d_1': 'a Contratar novos talentos.',\n",
       " 'P3_d_2': 'b Reter talentos.',\n",
       " 'P3_d_3': 'c Convencer a empresa a aumentar os investimentos na área de dados.',\n",
       " 'P3_d_4': 'd Gestão de equipes no ambiente remoto.',\n",
       " 'P3_d_5': 'e Gestão de projetos envolvendo áreas multidisciplinares da empresa.',\n",
       " 'P3_d_6': 'f Organizar as informações e garantir a qualidade e confiabilidade.',\n",
       " 'P3_d_7': 'g Conseguir processar e armazenar um alto volume de dados.',\n",
       " 'P3_d_8': 'h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.',\n",
       " 'P3_d_9': 'i Desenvolver e manter modelos Machine Learning em produção.',\n",
       " 'P3_d_10': 'j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.',\n",
       " 'P3_d_11': 'k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.',\n",
       " 'P3_d_12': 'Conseguir levar inovação para a empresa através dos dados.',\n",
       " 'P3_d_13': 'Garantir retorno do investimento (ROI) em projetos de dados.',\n",
       " 'P3_d_14': 'Dividir o tempo entre entregas técnicas e gestão.',\n",
       " 'P4_a': 'Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?',\n",
       " 'P4_a_1': 'Atuacao',\n",
       " 'P4_b': 'Quais das fontes de dados listadas você já analisou ou processou no trabalho?',\n",
       " 'P4_b_1': 'Dados relacionais (estruturados em bancos SQL',\n",
       " 'P4_b_2': 'Dados armazenados em bancos NoSQL',\n",
       " 'P4_b_3': 'Imagens',\n",
       " 'P4_b_4': 'Textos/Documentos',\n",
       " 'P4_b_5': 'Vídeos',\n",
       " 'P4_b_6': 'Áudios',\n",
       " 'P4_b_7': 'Planilhas',\n",
       " 'P4_b_8': 'Dados georeferenciados',\n",
       " 'P4_c': 'Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?',\n",
       " 'P4_c_1': 'Dados relacionais (estruturados em bancos SQL',\n",
       " 'P4_c_2': 'Dados armazenados em bancos NoSQL',\n",
       " 'P4_c_3': 'Imagens',\n",
       " 'P4_c_4': 'Textos/Documentos',\n",
       " 'P4_c_5': 'Vídeos',\n",
       " 'P4_c_6': 'Áudios',\n",
       " 'P4_c_7': 'Planilhas',\n",
       " 'P4_c_8': 'Dados georeferenciados',\n",
       " 'P4_d': 'Quais das linguagens listadas abaixo você utiliza no trabalho?',\n",
       " 'P4_d_1': 'SQL',\n",
       " 'P4_d_2': 'R ',\n",
       " 'P4_d_3': 'Python',\n",
       " 'P4_d_4': 'C/C++/C#',\n",
       " 'P4_d_5': '.NET',\n",
       " 'P4_d_6': 'Java',\n",
       " 'P4_d_7': 'Julia',\n",
       " 'P4_d_8': 'SAS/Stata',\n",
       " 'P4_d_9': 'Visual Basic/VBA',\n",
       " 'P4_d_10': 'Scala',\n",
       " 'P4_d_11': 'Matlab',\n",
       " 'P4_d_12': 'PHP',\n",
       " 'P4_d_13': 'Javascript',\n",
       " 'P4_d_14': 'Não utilizo nenhuma linguagem',\n",
       " 'P4_e': 'Entre as linguagens listadas abaixo, qual é a que você mais utiliza no trabalho?',\n",
       " 'P4_f': 'Entre as linguagens listadas abaixo, qual é a sua preferida?',\n",
       " 'P4_g': 'Quais das opções de Cloud listadas abaixo você utiliza no trabalho?',\n",
       " 'P4_g_1': 'MySQL',\n",
       " 'P4_g_2': 'Oracle',\n",
       " 'P4_g_3': 'SQL SERVER',\n",
       " 'P4_f_4': 'Amazon Aurora ou RDS',\n",
       " 'P4_f_5': 'DynamoDB',\n",
       " 'P4_f_6': 'CoachDB',\n",
       " 'P4_f_7': 'Cassandra',\n",
       " 'P4_f_8': 'MongoDB',\n",
       " 'P4_f_9': 'MariaDB',\n",
       " 'P4_f_10': 'Datomic',\n",
       " 'P4_f_11': 'S3',\n",
       " 'P4_f_12': 'PostgreSQL',\n",
       " 'P4_f_13': 'ElasticSearch',\n",
       " 'P4_f_14': 'DB2',\n",
       " 'P4_f_15': 'Microsoft Access',\n",
       " 'P4_f_16': 'SQLite',\n",
       " 'P4_f_17': 'Sybase',\n",
       " 'P4_f_18': 'Firebase',\n",
       " 'P4_f_19': 'Vertica',\n",
       " 'P4_f_20': 'Redis',\n",
       " 'P4_f_21': 'Neo4J',\n",
       " 'P4_f_22': 'Google BigQuery',\n",
       " 'P4_f_23': 'Google Firestore',\n",
       " 'P4_f_24': 'Amazon Redshift',\n",
       " 'P4_f_25': 'Amazon Athena',\n",
       " 'P4_f_26': 'Snowflake',\n",
       " 'P4_f_27': 'Databricks',\n",
       " 'P4_f_28': 'HBase',\n",
       " 'P4_f_29': 'Presto',\n",
       " 'P4_f_30': 'Splunk',\n",
       " 'P4_f_31': 'SAP HANA',\n",
       " 'P4_f_32': 'Hive',\n",
       " 'P4_f_33': 'Firebird',\n",
       " 'P4_h': 'Dentre as opções listadas, qual sua Cloud preferida?',\n",
       " 'P4_h_1': 'Azure (Microsoft',\n",
       " 'P4_h_2': 'Amazon Web Services (AWS',\n",
       " 'P4_h_3': 'Google Cloud (GCP',\n",
       " 'P4_i': 'Microsoft PowerBI',\n",
       " 'P4_i_1': 'Microsoft PowerBI',\n",
       " 'P4_i_2': 'Qlik View/Qlik Sense',\n",
       " 'P4_i_3': 'Tableau',\n",
       " 'P4_i_4': 'Metabase',\n",
       " 'P4_i_5': 'Superset',\n",
       " 'P4_i_6': 'Redash',\n",
       " 'P4_i_7': 'MicroStrategy',\n",
       " 'P4_i_8': 'IBM Analytics/Cognos',\n",
       " 'P4_i_9': 'SAP Business Objects',\n",
       " 'P4_i_10': 'Oracle Business Intelligence',\n",
       " 'P4_i_11': 'Amazon QuickSight',\n",
       " 'P4_i_12': 'Salesforce/Einstein Analytics',\n",
       " 'P4_i_13': 'Mode',\n",
       " 'P4_i_14': 'Alteryx',\n",
       " 'P4_i_15': 'Birst',\n",
       " 'P4_i_16': 'Looker',\n",
       " 'P4_i_17': 'Google Data Studio',\n",
       " 'P4_i_18': 'SAS Visual Analytics',\n",
       " 'P4_i_19': 'Grafana',\n",
       " 'P4_i_20': 'TIBCO Spotfire',\n",
       " 'P4_i_21': 'Pentaho',\n",
       " 'P4_i_22': 'Fazemos todas as análises utilizando apenas Excel ou planilhas do google',\n",
       " 'P4_i_23': 'Não utilizo nenhuma ferramenta de BI no trabalho',\n",
       " 'P5_a': 'Qual seu objetivo na área de dados?',\n",
       " 'P5_b': 'Qual oportunidade você está buscando?',\n",
       " 'P5_c': 'Há quanto tempo você busca uma oportunidade na área de dados?',\n",
       " 'P5_d': 'Como tem sido a busca por um emprego na área de dados?',\n",
       " 'P6_a': 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?',\n",
       " 'P6_a_1': 'Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.',\n",
       " 'P6_a_2': 'Realizo construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc.',\n",
       " 'P6_a_3': 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.',\n",
       " 'P6_a_4': 'Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.',\n",
       " 'P6_a_5': 'Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.',\n",
       " 'P6_a_6': 'Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.',\n",
       " 'P6_a_7': 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.',\n",
       " 'P6_a_8': 'Cuido da qualidade dos dados, metadados e dicionário de dados.',\n",
       " 'P6_a_9': 'Nenhuma das opções listadas refletem meu dia a dia.',\n",
       " 'P6_b': 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?',\n",
       " 'P6_b_1': 'Scripts Python',\n",
       " 'P6_b_2': 'SQL & Stored Procedures',\n",
       " 'P6_b_3': 'Apache Airflow',\n",
       " 'P6_b_4': 'Luigi',\n",
       " 'P6_b_5': 'AWS Glue',\n",
       " 'P6_b_6': 'Talend',\n",
       " 'P6_b_7': 'Pentaho',\n",
       " 'P6_b_8': 'Alteryx',\n",
       " 'P6_b_9': 'Stitch',\n",
       " 'P6_b_10': 'Fivetran',\n",
       " 'P6_b_11': 'Google Dataflow',\n",
       " 'P6_b_12': 'Oracle Data Integrator',\n",
       " 'P6_b_13': 'IBM DataStage',\n",
       " 'P6_b_14': 'SAP BW ETL',\n",
       " 'P6_b_15': 'SQL Server Integration Services (SSIS',\n",
       " 'P6_b_16': 'SAS Data Integration',\n",
       " 'P6_b_17': 'Qlik Sense',\n",
       " 'P6_b_18': 'Knime',\n",
       " 'P6_b_19': 'Não utilizo ferramentas de ETL',\n",
       " 'P6_c': 'Sua organização possui um Data Lake?',\n",
       " 'P6_d': 'Qual tecnologia utilizada como plataforma do Data Lake?',\n",
       " 'P6_e': 'Sua organização possui um Data Warehouse?',\n",
       " 'P6_f': 'Qual tecnologia utilizada como plataforma do Data Warehouse?',\n",
       " 'P6_g': 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?',\n",
       " 'P6_g_1': 'great_expectations',\n",
       " 'P6_g_2': 'dbt',\n",
       " 'P6_g_3': 'AWS Deequ',\n",
       " 'P6_g_4': 'Apache Griffin',\n",
       " 'P6_g_5': 'Datafold',\n",
       " 'P6_g_6': 'Amundsen',\n",
       " 'P6_g_7': 'Monte Carlo',\n",
       " 'P6_g_8': 'SODA',\n",
       " 'P6_g_9': 'Big Eye',\n",
       " 'P6_g_10': 'Data Band',\n",
       " 'P6_g_11': 'Anomalo',\n",
       " 'P6_g_l': 'Metaplane',\n",
       " 'P6_g_m': 'Acceldata',\n",
       " 'P6_h': 'Em qual das opções abaixo você gasta a maior parte do seu tempo?',\n",
       " 'P6_h_1': 'Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.',\n",
       " 'P6_h_2': 'Realizando construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc.',\n",
       " 'P6_h_3': 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.',\n",
       " 'P6_h_4': 'Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.',\n",
       " 'P6_h_5': 'Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.',\n",
       " 'P6_h_6': 'Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.',\n",
       " 'P6_h_7': 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.',\n",
       " 'P6_h_8': 'Cuidando da qualidade dos dados, metadados e dicionário de dados.',\n",
       " 'P6_h_9': 'Nenhuma das opções listadas refletem meu dia a dia.',\n",
       " 'P7_1': 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?',\n",
       " 'P7_a_1': 'Processo e analiso dados utilizando linguagens de programação como Python, R etc.',\n",
       " 'P7_a_2': 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.',\n",
       " 'P7_a_3': 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.',\n",
       " 'P7_a_4': 'Utilizo APIs para extrair dados e complementar minhas análises.',\n",
       " 'P7_a_5': 'Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.',\n",
       " 'P7_a_6': 'Desenvolvo/cuido da manutenção de ETLs utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.',\n",
       " 'P7_a_7': 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.',\n",
       " 'P7_a_8': 'Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.',\n",
       " 'P7_a_9': 'Utilizo ferramentas avançadas de estatística como SAS',\n",
       " 'P7_a_10': 'Nenhuma das opções listadas refletem meu dia a dia.',\n",
       " 'P7_b': 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?',\n",
       " 'P7_b_1': 'Scripts Python',\n",
       " 'P7_b_2': 'SQL & Stored Procedures',\n",
       " 'P7_b_3': 'Apache Airflow',\n",
       " 'P7_b_4': 'Luigi',\n",
       " 'P7_b_5': 'AWS Glue',\n",
       " 'P7_b_6': 'Talend',\n",
       " 'P7_b_7': 'Pentaho',\n",
       " 'P7_b_8': 'Alteryx',\n",
       " 'P7_b_9': 'Stitch',\n",
       " 'P7_b_10': 'Fivetran',\n",
       " 'P7_b_11': 'Google Dataflow',\n",
       " 'P7_b_12': 'Oracle Data Integrator',\n",
       " 'P7_b_13': 'IBM DataStage',\n",
       " 'P7_b_14': 'SAP BW ETL',\n",
       " 'P7_b_15': 'SQL Server Integration Services (SSIS',\n",
       " 'P7_b_16': 'SAS Data Integration',\n",
       " 'P7_b_17': 'Qlik Sense',\n",
       " 'P7_b_18': 'Knime',\n",
       " 'P7_b_19': 'Databricks',\n",
       " 'P7_b_20': 'Não utilizo ferramentas de ETL',\n",
       " 'P7_c': 'Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?',\n",
       " 'P7_c_1': 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.',\n",
       " 'P7_c_2': '\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.',\n",
       " 'P7_c_3': 'Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.',\n",
       " 'P7_c_4': 'Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.',\n",
       " 'P7_c_5': 'Minha empresa não utiliza essas ferramentas.',\n",
       " 'P7_c_6': 'Não sei informar.',\n",
       " 'P7_d': 'Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?',\n",
       " 'P7_d_1': 'Processando e analisando dados utilizando linguagens de programação como Python, R etc.',\n",
       " 'P7_d_2': 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.',\n",
       " 'P7_d_3': 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.',\n",
       " 'P7_d_4': 'Utilizando APIs para extrair dados e complementar minhas análises.',\n",
       " 'P7_d_5': 'Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.',\n",
       " 'P7_d_6': 'Desenvolvendo/cuidando da manutenção de ETLs utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.',\n",
       " 'P7_d_7': 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.',\n",
       " 'P7_d_8': 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.',\n",
       " 'P7_d_9': 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.',\n",
       " 'P7_d_10': 'Nenhuma das opções listadas refletem meu dia a dia.',\n",
       " 'P8_a': 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?',\n",
       " 'P8_a_1': 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.',\n",
       " 'P8_a_2': 'Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.',\n",
       " 'P8_a_3': 'Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.',\n",
       " 'P8_a_4': 'Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).',\n",
       " 'P8_a_5': 'Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.',\n",
       " 'P8_a_6': 'Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.',\n",
       " 'P8_a_7': 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc',\n",
       " 'P8_a_8': 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.',\n",
       " 'P8_a_9': 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.',\n",
       " 'P8_a_10': 'Crio e gerencio soluções de Feature Store e cultura de MLOps.',\n",
       " 'P8_a_11': 'Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.',\n",
       " 'P8_b': 'Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?',\n",
       " 'P8_b_1': 'Utilizo modelos de regressão (linear, logística, GLM',\n",
       " 'P8_b_2': 'Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação',\n",
       " 'P8_b_3': 'Desenvolvo sistemas de recomendação (RecSys',\n",
       " 'P8_b_4': 'Utilizo métodos estatísticos Bayesianos para analisar dados',\n",
       " 'P8_b_5': 'Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados',\n",
       " 'P8_b_6': 'Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados',\n",
       " 'P8_b_7': 'Utilizo cadeias de Markov ou HMMs para realizar análises de dados',\n",
       " 'P8_b_8': 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc',\n",
       " 'P8_b_9': 'Realizo previsões através de modelos de Séries Temporais (Time Series',\n",
       " 'P8_b_10': 'Utilizo modelos de Reinforcement Learning (aprendizado por reforço',\n",
       " 'P8_b_11': 'Utilizo modelos de Machine Learning para detecção de fraude',\n",
       " 'P8_b_l': 'Utilizo métodos de Visão Computacional',\n",
       " 'P8_b_m': 'Utilizo modelos de Detecção de Churn',\n",
       " 'P8_3': 'Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?',\n",
       " 'P8_c_1': 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc',\n",
       " 'P8_c_2': 'Planilhas (Excel, Google Sheets etc',\n",
       " 'P8_c_3': 'Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda',\n",
       " 'P8_c_4': 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc',\n",
       " 'P8_c_5': 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc',\n",
       " 'P8_c_6': 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc',\n",
       " 'P8_c_7': 'Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc',\n",
       " 'P8_c_8': 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc',\n",
       " 'P8_c_9': 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc',\n",
       " 'P8_c_10': 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc',\n",
       " 'P8_c_11': 'Ferramentas de estatística avançada como SPSS, SAS, etc.',\n",
       " 'P8_d': 'Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?',\n",
       " 'P8_d_1': 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.',\n",
       " 'P8_d_2': 'Coletando e limpando os dados que uso para análise e modelagem.',\n",
       " 'P8_d_3': 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.',\n",
       " 'P8_d_4': 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).',\n",
       " 'P8_d_5': 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.',\n",
       " 'P8_d_6': 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.',\n",
       " 'P8_d_7': 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.',\n",
       " 'P8_d_8': 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.',\n",
       " 'P8_d_9': 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.',\n",
       " 'P8_d_10': 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.',\n",
       " 'P8_d_11': 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('P1_a ', 'Idade')</th>\n",
       "      <th>('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')</th>\n",
       "      <th>('P2_l_2 ', 'Salário atual não corresponde ao mercado')</th>\n",
       "      <th>('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')</th>\n",
       "      <th>('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')</th>\n",
       "      <th>('P2_l_5 ', 'Gostaria de receber mais benefícios')</th>\n",
       "      <th>('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')</th>\n",
       "      <th>('P2_l_7 ', 'Falta de maturidade analítica na empresa')</th>\n",
       "      <th>('P2_o_1 ', 'Remuneração/Salário')</th>\n",
       "      <th>('P2_o_2 ', 'Benefícios')</th>\n",
       "      <th>...</th>\n",
       "      <th>('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')</th>\n",
       "      <th>('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')</th>\n",
       "      <th>('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')</th>\n",
       "      <th>('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')</th>\n",
       "      <th>('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')</th>\n",
       "      <th>('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')</th>\n",
       "      <th>('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')</th>\n",
       "      <th>('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')</th>\n",
       "      <th>('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')</th>\n",
       "      <th>('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4197.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>960.000000</td>\n",
       "      <td>3694.000000</td>\n",
       "      <td>3694.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>629.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.169168</td>\n",
       "      <td>0.436458</td>\n",
       "      <td>0.389583</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.321875</td>\n",
       "      <td>0.184375</td>\n",
       "      <td>0.142708</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.750677</td>\n",
       "      <td>0.192745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478537</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.095390</td>\n",
       "      <td>0.057234</td>\n",
       "      <td>0.065183</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>0.031797</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.015898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.902803</td>\n",
       "      <td>0.496205</td>\n",
       "      <td>0.487910</td>\n",
       "      <td>0.249574</td>\n",
       "      <td>0.467439</td>\n",
       "      <td>0.387992</td>\n",
       "      <td>0.349957</td>\n",
       "      <td>0.486452</td>\n",
       "      <td>0.432680</td>\n",
       "      <td>0.394508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499937</td>\n",
       "      <td>0.432203</td>\n",
       "      <td>0.468494</td>\n",
       "      <td>0.293986</td>\n",
       "      <td>0.232473</td>\n",
       "      <td>0.247045</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.175598</td>\n",
       "      <td>0.136908</td>\n",
       "      <td>0.125182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ('P1_a ', 'Idade')  \\\n",
       "count         4197.000000   \n",
       "mean            31.169168   \n",
       "std              6.902803   \n",
       "min             18.000000   \n",
       "25%             26.000000   \n",
       "50%             30.000000   \n",
       "75%             35.000000   \n",
       "max             54.000000   \n",
       "\n",
       "       ('P2_l_1 ', 'Falta de oportunidade de crescimento no emprego atual')  \\\n",
       "count                                         960.000000                      \n",
       "mean                                            0.436458                      \n",
       "std                                             0.496205                      \n",
       "min                                             0.000000                      \n",
       "25%                                             0.000000                      \n",
       "50%                                             0.000000                      \n",
       "75%                                             1.000000                      \n",
       "max                                             1.000000                      \n",
       "\n",
       "       ('P2_l_2 ', 'Salário atual não corresponde ao mercado')  \\\n",
       "count                                         960.000000         \n",
       "mean                                            0.389583         \n",
       "std                                             0.487910         \n",
       "min                                             0.000000         \n",
       "25%                                             0.000000         \n",
       "50%                                             0.000000         \n",
       "75%                                             1.000000         \n",
       "max                                             1.000000         \n",
       "\n",
       "       ('P2_l_3 ', 'Não tenho uma boa relação com meu líder/gestor')  \\\n",
       "count                                         960.000000               \n",
       "mean                                            0.066667               \n",
       "std                                             0.249574               \n",
       "min                                             0.000000               \n",
       "25%                                             0.000000               \n",
       "50%                                             0.000000               \n",
       "75%                                             0.000000               \n",
       "max                                             1.000000               \n",
       "\n",
       "       ('P2_l_4 ', 'Gostaria de trabalhar em em outra área de atuação')  \\\n",
       "count                                         960.000000                  \n",
       "mean                                            0.321875                  \n",
       "std                                             0.467439                  \n",
       "min                                             0.000000                  \n",
       "25%                                             0.000000                  \n",
       "50%                                             0.000000                  \n",
       "75%                                             1.000000                  \n",
       "max                                             1.000000                  \n",
       "\n",
       "       ('P2_l_5 ', 'Gostaria de receber mais benefícios')  \\\n",
       "count                                         960.000000    \n",
       "mean                                            0.184375    \n",
       "std                                             0.387992    \n",
       "min                                             0.000000    \n",
       "25%                                             0.000000    \n",
       "50%                                             0.000000    \n",
       "75%                                             0.000000    \n",
       "max                                             1.000000    \n",
       "\n",
       "       ('P2_l_6 ', 'O clima de trabalho/ambiente não é bom')  \\\n",
       "count                                         960.000000       \n",
       "mean                                            0.142708       \n",
       "std                                             0.349957       \n",
       "min                                             0.000000       \n",
       "25%                                             0.000000       \n",
       "50%                                             0.000000       \n",
       "75%                                             0.000000       \n",
       "max                                             1.000000       \n",
       "\n",
       "       ('P2_l_7 ', 'Falta de maturidade analítica na empresa')  \\\n",
       "count                                         960.000000         \n",
       "mean                                            0.383333         \n",
       "std                                             0.486452         \n",
       "min                                             0.000000         \n",
       "25%                                             0.000000         \n",
       "50%                                             0.000000         \n",
       "75%                                             1.000000         \n",
       "max                                             1.000000         \n",
       "\n",
       "       ('P2_o_1 ', 'Remuneração/Salário')  ('P2_o_2 ', 'Benefícios')  ...  \\\n",
       "count                         3694.000000                3694.000000  ...   \n",
       "mean                             0.750677                   0.192745  ...   \n",
       "std                              0.432680                   0.394508  ...   \n",
       "min                              0.000000                   0.000000  ...   \n",
       "25%                              1.000000                   0.000000  ...   \n",
       "50%                              1.000000                   0.000000  ...   \n",
       "75%                              1.000000                   0.000000  ...   \n",
       "max                              1.000000                   1.000000  ...   \n",
       "\n",
       "       ('P8_d_2 ', 'Coletando e limpando os dados que uso para análise e modelagem.')  \\\n",
       "count                                         629.000000                                \n",
       "mean                                            0.478537                                \n",
       "std                                             0.499937                                \n",
       "min                                             0.000000                                \n",
       "25%                                             0.000000                                \n",
       "50%                                             0.000000                                \n",
       "75%                                             1.000000                                \n",
       "max                                             1.000000                                \n",
       "\n",
       "       ('P8_d_3 ', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.')  \\\n",
       "count                                         629.000000                                                                                            \n",
       "mean                                            0.248013                                                                                            \n",
       "std                                             0.432203                                                                                            \n",
       "min                                             0.000000                                                                                            \n",
       "25%                                             0.000000                                                                                            \n",
       "50%                                             0.000000                                                                                            \n",
       "75%                                             0.000000                                                                                            \n",
       "max                                             1.000000                                                                                            \n",
       "\n",
       "       ('P8_d_4 ', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).')  \\\n",
       "count                                         629.000000                                                                                 \n",
       "mean                                            0.324324                                                                                 \n",
       "std                                             0.468494                                                                                 \n",
       "min                                             0.000000                                                                                 \n",
       "25%                                             0.000000                                                                                 \n",
       "50%                                             0.000000                                                                                 \n",
       "75%                                             1.000000                                                                                 \n",
       "max                                             1.000000                                                                                 \n",
       "\n",
       "       ('P8_d_5 ', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.')  \\\n",
       "count                                         629.000000                                                               \n",
       "mean                                            0.095390                                                               \n",
       "std                                             0.293986                                                               \n",
       "min                                             0.000000                                                               \n",
       "25%                                             0.000000                                                               \n",
       "50%                                             0.000000                                                               \n",
       "75%                                             0.000000                                                               \n",
       "max                                             1.000000                                                               \n",
       "\n",
       "       ('P8_d_6 ', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.')  \\\n",
       "count                                         629.000000                                                                                                         \n",
       "mean                                            0.057234                                                                                                         \n",
       "std                                             0.232473                                                                                                         \n",
       "min                                             0.000000                                                                                                         \n",
       "25%                                             0.000000                                                                                                         \n",
       "50%                                             0.000000                                                                                                         \n",
       "75%                                             0.000000                                                                                                         \n",
       "max                                             1.000000                                                                                                         \n",
       "\n",
       "       ('P8_d_7 ', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.')  \\\n",
       "count                                         629.000000                                                                    \n",
       "mean                                            0.065183                                                                    \n",
       "std                                             0.247045                                                                    \n",
       "min                                             0.000000                                                                    \n",
       "25%                                             0.000000                                                                    \n",
       "50%                                             0.000000                                                                    \n",
       "75%                                             0.000000                                                                    \n",
       "max                                             1.000000                                                                    \n",
       "\n",
       "       ('P8_d_8 ', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.')  \\\n",
       "count                                         629.000000                                                                   \n",
       "mean                                            0.006359                                                                   \n",
       "std                                             0.079555                                                                   \n",
       "min                                             0.000000                                                                   \n",
       "25%                                             0.000000                                                                   \n",
       "50%                                             0.000000                                                                   \n",
       "75%                                             0.000000                                                                   \n",
       "max                                             1.000000                                                                   \n",
       "\n",
       "       ('P8_d_9 ', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.')  \\\n",
       "count                                         629.000000                                             \n",
       "mean                                            0.031797                                             \n",
       "std                                             0.175598                                             \n",
       "min                                             0.000000                                             \n",
       "25%                                             0.000000                                             \n",
       "50%                                             0.000000                                             \n",
       "75%                                             0.000000                                             \n",
       "max                                             1.000000                                             \n",
       "\n",
       "       ('P8_d_10 ', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.')  \\\n",
       "count                                         629.000000                                     \n",
       "mean                                            0.019078                                     \n",
       "std                                             0.136908                                     \n",
       "min                                             0.000000                                     \n",
       "25%                                             0.000000                                     \n",
       "50%                                             0.000000                                     \n",
       "75%                                             0.000000                                     \n",
       "max                                             1.000000                                     \n",
       "\n",
       "       ('P8_d_11 ', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.)')  \n",
       "count                                         629.000000                                                                           \n",
       "mean                                            0.015898                                                                           \n",
       "std                                             0.125182                                                                           \n",
       "min                                             0.000000                                                                           \n",
       "25%                                             0.000000                                                                           \n",
       "50%                                             0.000000                                                                           \n",
       "75%                                             0.000000                                                                           \n",
       "max                                             1.000000                                                                           \n",
       "\n",
       "[8 rows x 284 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('features_map.json', 'w', encoding=\"utf-8\") as json_file:\n",
    "    json.dump(features, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {}\n",
    "\n",
    "for column in df.columns:\n",
    "    column_stripped = column.strip(\"(')\")\n",
    "    column_splitted = column_stripped.replace(\"'\", \"\").split(', ')\n",
    "\n",
    "    column_mapping[column] = column_splitted[0].strip()\n",
    "\n",
    "    #print(column[0])\n",
    "    #print(', '.join(column[1:]))\n",
    "    #print('-----')#features[column[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P0</th>\n",
       "      <th>P1_a</th>\n",
       "      <th>P1_a_1</th>\n",
       "      <th>P1_b</th>\n",
       "      <th>P1_c</th>\n",
       "      <th>P1_d</th>\n",
       "      <th>P1_e</th>\n",
       "      <th>P1_f</th>\n",
       "      <th>P1_g</th>\n",
       "      <th>P1_i</th>\n",
       "      <th>...</th>\n",
       "      <th>P8_d_2</th>\n",
       "      <th>P8_d_3</th>\n",
       "      <th>P8_d_4</th>\n",
       "      <th>P8_d_5</th>\n",
       "      <th>P8_d_6</th>\n",
       "      <th>P8_d_7</th>\n",
       "      <th>P8_d_8</th>\n",
       "      <th>P8_d_9</th>\n",
       "      <th>P8_d_10</th>\n",
       "      <th>P8_d_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zzqzz3l9ily8nuo2m7wyzzqzz3w48o96</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35-39</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não acredito que minha experiência profissiona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Distrito Federal (DF)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zzls2oftfn9law393oezzls2ofhvfpzd</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sim, acredito que a minha a experiência profis...</td>\n",
       "      <td>Aprovação em processos seletivos/entrevistas</td>\n",
       "      <td>True</td>\n",
       "      <td>Pará (PA)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zzdwqzfqqp1ypc7ps6m0hzzdwqz292yi</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Distrito Federal (DF)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zzbqh3uy7yk7k9qmkzzbqtb4s9faqspl</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25-29</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Minas Gerais (MG)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zzaf1m95yan929rb94wzzaf1mekhvhpg</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45-49</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não acredito que minha experiência profissiona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Pará (PA)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 353 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 P0  P1_a P1_a_1       P1_b    P1_c P1_d  \\\n",
       "0  zzqzz3l9ily8nuo2m7wyzzqzz3w48o96  39.0  35-39  Masculino   Parda  Não   \n",
       "1  zzls2oftfn9law393oezzls2ofhvfpzd  32.0  30-34  Masculino   Parda  Não   \n",
       "2  zzdwqzfqqp1ypc7ps6m0hzzdwqz292yi  53.0  50-54  Masculino  Branca  Não   \n",
       "3  zzbqh3uy7yk7k9qmkzzbqtb4s9faqspl  27.0  25-29  Masculino  Branca  Não   \n",
       "4  zzaf1m95yan929rb94wzzaf1mekhvhpg  46.0  45-49   Feminino  Branca  Não   \n",
       "\n",
       "                                                P1_e  \\\n",
       "0  Não acredito que minha experiência profissiona...   \n",
       "1  Sim, acredito que a minha a experiência profis...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  Não acredito que minha experiência profissiona...   \n",
       "\n",
       "                                           P1_f  P1_g                   P1_i  \\\n",
       "0                                           NaN  True  Distrito Federal (DF)   \n",
       "1  Aprovação em processos seletivos/entrevistas  True              Pará (PA)   \n",
       "2                                           NaN  True  Distrito Federal (DF)   \n",
       "3                                           NaN  True      Minas Gerais (MG)   \n",
       "4                                           NaN  True              Pará (PA)   \n",
       "\n",
       "   ... P8_d_2 P8_d_3 P8_d_4 P8_d_5 P8_d_6 P8_d_7 P8_d_8 P8_d_9 P8_d_10 P8_d_11  \n",
       "0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
       "1  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
       "2  ...    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0  \n",
       "3  ...    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0  \n",
       "4  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 353 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P1_a'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1_a_1</th>\n",
       "      <th>P1_b</th>\n",
       "      <th>P1_c</th>\n",
       "      <th>P1_d</th>\n",
       "      <th>P1_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35-39</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sudeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30-34</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Parda</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50-54</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>Sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-29</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45-49</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>Branca</td>\n",
       "      <td>Não</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  P1_a_1       P1_b    P1_c P1_d     P1_k\n",
       "0  35-39  Masculino   Parda  Não  Sudeste\n",
       "1  30-34  Masculino   Parda  Não      NaN\n",
       "2  50-54  Masculino  Branca  Não      Sul\n",
       "3  25-29  Masculino  Branca  Não      NaN\n",
       "4  45-49   Feminino  Branca  Não      NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['P1_a_1', 'P1_b', 'P1_c', 'P1_d', 'P1_k']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P1_b\n",
       "Masculino               3194\n",
       "Feminino                1056\n",
       "Prefiro não informar      12\n",
       "NaN                        9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P1_b'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P1_c\n",
       "Branca                  2744\n",
       "Parda                   1054\n",
       "Preta                    291\n",
       "Amarela                  128\n",
       "Prefiro não informar      26\n",
       "Outra                     17\n",
       "Indígena                  11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P1_c'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P1_d\n",
       "Não                     4198\n",
       "Sim                       54\n",
       "Prefiro não informar      19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P1_d'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P1_k\n",
       "NaN             3499\n",
       "Sudeste          356\n",
       "Nordeste         190\n",
       "Sul              121\n",
       "Centro-oeste      58\n",
       "Norte             47\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P1_k'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P6_e\n",
       "NaN      3598\n",
       "True      553\n",
       "False     120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P6_e'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lazypredict\n",
      "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: click in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from lazypredict) (8.1.7)\n",
      "Collecting scikit-learn (from lazypredict)\n",
      "  Downloading scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from lazypredict) (2.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from lazypredict) (4.66.2)\n",
      "Collecting joblib (from lazypredict)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting lightgbm (from lazypredict)\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xgboost (from lazypredict)\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from click->lazypredict) (0.4.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from lightgbm->lazypredict) (1.26.4)\n",
      "Collecting scipy (from lightgbm->lazypredict)\n",
      "  Downloading scipy-1.12.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     -------------------- ------------------- 30.7/60.4 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.4 kB 650.2 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.4 kB 650.2 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 356.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from pandas->lazypredict) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from pandas->lazypredict) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from pandas->lazypredict) (2024.1)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->lazypredict)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->lazypredict) (1.16.0)\n",
      "Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 92.2/302.2 kB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 225.3/302.2 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  297.0/302.2 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 8.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 28.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/10.6 MB 25.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.8/10.6 MB 27.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.9/10.6 MB 27.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.8/10.6 MB 25.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 26.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.5/10.6 MB 26.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.8/10.6 MB 19.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.3/10.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/99.8 MB 27.1 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.8/99.8 MB 27.1 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.8/99.8 MB 27.1 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.8/99.8 MB 27.1 MB/s eta 0:00:04\n",
      "   ---------------------------------------- 0.8/99.8 MB 27.1 MB/s eta 0:00:04\n",
      "    --------------------------------------- 1.9/99.8 MB 7.3 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 4.8/99.8 MB 15.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 6.3/99.8 MB 17.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 9.6/99.8 MB 23.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 9.7/99.8 MB 21.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 11.1/99.8 MB 38.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 12.2/99.8 MB 36.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 13.4/99.8 MB 34.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 15.4/99.8 MB 34.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 17.3/99.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 17.7/99.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 18.2/99.8 MB 25.2 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 19.3/99.8 MB 23.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 20.8/99.8 MB 25.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 22.1/99.8 MB 25.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 23.6/99.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 25.2/99.8 MB 26.2 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 26.1/99.8 MB 26.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 28.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 30.9/99.8 MB 31.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 32.3/99.8 MB 31.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 33.8/99.8 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 35.3/99.8 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 36.8/99.8 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 38.3/99.8 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 39.9/99.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 41.4/99.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 42.8/99.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 44.4/99.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 45.6/99.8 MB 32.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 45.7/99.8 MB 29.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 46.7/99.8 MB 27.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 48.0/99.8 MB 26.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 49.0/99.8 MB 25.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 49.9/99.8 MB 23.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 51.1/99.8 MB 22.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 52.6/99.8 MB 23.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 52.8/99.8 MB 22.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 53.3/99.8 MB 19.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 54.4/99.8 MB 19.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 56.2/99.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 56.8/99.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 57.1/99.8 MB 19.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 58.0/99.8 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 59.9/99.8 MB 21.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 60.6/99.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 61.0/99.8 MB 19.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 62.1/99.8 MB 18.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 63.2/99.8 MB 20.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 64.4/99.8 MB 21.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 65.9/99.8 MB 21.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 65.9/99.8 MB 19.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 66.4/99.8 MB 18.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 67.8/99.8 MB 20.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 69.1/99.8 MB 21.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 70.6/99.8 MB 20.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 72.0/99.8 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 73.4/99.8 MB 24.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 74.9/99.8 MB 24.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 76.4/99.8 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 77.8/99.8 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 79.4/99.8 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 80.9/99.8 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 82.4/99.8 MB 31.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 83.3/99.8 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.2/99.8 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.8/99.8 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 85.2/99.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 85.6/99.8 MB 21.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 86.0/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 86.6/99.8 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 87.5/99.8 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 88.5/99.8 MB 18.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.5/99.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 90.7/99.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.6/99.8 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.7/99.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.9/99.8 MB 17.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.5/99.8 MB 19.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 95.8/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 96.5/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.3/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  98.1/99.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.2/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading scipy-1.12.0-cp312-cp312-win_amd64.whl (45.8 MB)\n",
      "   ---------------------------------------- 0.0/45.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/45.8 MB 20.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 2.4/45.8 MB 25.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.8/45.8 MB 26.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 4.0/45.8 MB 25.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 4.5/45.8 MB 19.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 5.5/45.8 MB 19.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 7.2/45.8 MB 21.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.3/45.8 MB 22.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.3/45.8 MB 22.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 7.3/45.8 MB 22.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.3/45.8 MB 18.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 10.9/45.8 MB 19.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.6/45.8 MB 18.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 12.4/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 13.7/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.4/45.8 MB 19.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 15.2/45.8 MB 18.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 16.7/45.8 MB 19.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.4/45.8 MB 18.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.5/45.8 MB 23.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 18.0/45.8 MB 21.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.5/45.8 MB 19.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.9/45.8 MB 17.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.6/45.8 MB 16.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 20.4/45.8 MB 16.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 20.6/45.8 MB 15.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 20.8/45.8 MB 14.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 21.5/45.8 MB 13.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 21.8/45.8 MB 13.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.5/45.8 MB 13.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.9/45.8 MB 12.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.2/45.8 MB 12.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.2/45.8 MB 12.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.5/45.8 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 24.0/45.8 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.3/45.8 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.3/45.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.7/45.8 MB 9.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 27.3/45.8 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.0/45.8 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.8/45.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.8/45.8 MB 11.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.9/45.8 MB 12.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.8/45.8 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 32.7/45.8 MB 13.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 32.9/45.8 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.3/45.8 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 34.1/45.8 MB 15.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.9/45.8 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.7/45.8 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.8/45.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 36.6/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.4/45.8 MB 15.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.3/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.4/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.4/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.3/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.0/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.2/45.8 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/45.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.9/45.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.7/45.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.8/45.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.8/45.8 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, xgboost, scikit-learn, lightgbm, lazypredict\n",
      "Successfully installed joblib-1.3.2 lazypredict-0.2.12 lightgbm-4.3.0 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.3.0 xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install lazypredict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diogo_3y8emb6\\miniconda3\\envs\\responsible-ai-datahackers\\lib\\site-packages (from scikit-learn) (3.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['id', 'Idade', 'Faixa idade', 'Genero', 'Cor/raca/etnia', 'PCD', 'experiencia_profissional_prejudicada', 'aspectos_prejudicados', 'vive_no_brasil', 'Estado onde mora', 'uf onde mora', 'Regiao onde mora', 'Mudou de Estado?', 'Regiao de origem', 'Nivel de Ensino', 'Área de Formação', 'Qual sua situação atual de trabalho?', 'Setor', 'Numero de Funcionarios', 'Gestor?', 'Cargo como Gestor', 'Cargo Atual', 'Nivel', 'Faixa salarial', 'Quanto tempo de experiência na área de dados você tem?', 'Quanto tempo de experiência na área de TI/Engenharia de Software você teve antes de começar a trabalhar na área de dados?', 'Você está satisfeito na sua empresa atual?', 'Qual o principal motivo da sua insatisfação com a empresa atual?', 'Falta de oportunidade de crescimento no emprego atual', 'Salário atual não corresponde ao mercado', 'Não tenho uma boa relação com meu líder/gestor', 'Gostaria de trabalhar em em outra área de atuação', 'Gostaria de receber mais benefícios', 'O clima de trabalho/ambiente não é bom', 'Falta de maturidade analítica na empresa', 'Você participou de entrevistas de emprego nos últimos 6 meses?', 'Você pretende mudar de emprego nos próximos 6 meses?', 'Quais os principais critérios que você leva em consideração no momento de decidir onde trabalhar?', 'Remuneração/Salário', 'Benefícios', 'Propósito do trabalho e da empresa', 'Flexibilidade de trabalho remoto', 'Ambiente e clima de trabalho', 'Oportunidade de aprendizado e trabalhar com referências na área', 'Plano de carreira e oportunidades de crescimento profissional', 'Maturidade da empresa em termos de tecnologia e dados', 'Qualidade dos gestores e líderes', 'Reputação que a empresa tem no mercado', 'Atualmente qual a sua forma de trabalho?', 'Qual a forma de trabalho ideal para você?', 'Caso sua empresa decida pelo modelo 100% presencial qual será sua atitude?', 'Sua empresa passu por Layoff em 2022?', 'Qual o número aproximado de pessoas que atuam com dados na sua empresa hoje?', 'Quais desses papéis/cargos fazem parte do time (ou chapter) de dados da sua empresa?', 'Analytics Engineer', 'Engenharia de Dados/Data Engineer', 'Analista de Dados/Data Analyst', 'Cientista de Dados/Data Scientist', 'Database Administrator/DBA', 'Analista de Business Intelligence/BI', 'Arquiteto de Dados/Data Architect', 'Data Product Manager/DPM', 'Business Analyst', 'Quais dessas responsabilidades fazem parte da sua rotina atual de trabalho como gestor?', 'Pensar na visão de longo prazo de dados da empresa e fortalecimento da cultura analítica da companhia.', 'Organização de treinamentos e iniciativas com o objetivo de aumentar a maturidade analítica das áreas de negócios.', 'Atração, seleção e contratação de talentos para o time de dados.', 'Decisão sobre contratação de ferramentas e tecnologias relacionadas a dados.', 'Sou gestor da equipe responsável pela engenharia de dados e por manter o Data Lake da empresa como fonte única dos dados, garantindo a qualidade e confiabilidade da informação.', 'Sou gestor da equipe responsável pela entrega de dados, estudos, relatórios e dashboards para as áreas de negócio da empresa.', 'Sou gestor da equipe responsável por iniciativas e projetos envolvendo Inteligência Artificial e Machine Learning.', 'Apesar de ser gestor ainda atuo na parte técnica, construindo soluções/análises/modelos etc.', 'Gestão de projetos de dados, cuidando das etapas, equipes envolvidas, atingimento dos objetivos etc.', 'Gestão de produtos de dados, cuidando da visão dos produtos, backlog, feedback de usuários etc.', 'Gestão de pessoas, apoio no desenvolvimento das pessoas, evolução de carreira', 'Quais são os 3 maiores desafios que você tem como gestor no atual momento?', 'a Contratar novos talentos.', 'b Reter talentos.', 'c Convencer a empresa a aumentar os investimentos na área de dados.', 'd Gestão de equipes no ambiente remoto.', 'e Gestão de projetos envolvendo áreas multidisciplinares da empresa.', 'f Organizar as informações e garantir a qualidade e confiabilidade.', 'g Conseguir processar e armazenar um alto volume de dados.', 'h Conseguir gerar valor para as áreas de negócios através de estudos e experimentos.', 'i Desenvolver e manter modelos Machine Learning em produção.', 'j Gerenciar a expectativa das áreas de negócio em relação as entregas das equipes de dados.', 'k Garantir a manutenção dos projetos e modelos em produção, em meio ao crescimento da empresa.', 'Conseguir levar inovação para a empresa através dos dados.', 'Garantir retorno do investimento (ROI) em projetos de dados.', 'Dividir o tempo entre entregas técnicas e gestão.', 'Mesmo que esse não seja seu cargo formal, você considera que sua atuação no dia a dia, reflete alguma das opções listadas abaixo?', 'Atuacao', 'Quais das fontes de dados listadas você já analisou ou processou no trabalho?', 'Dados relacionais (estruturados em bancos SQL', 'Dados armazenados em bancos NoSQL', 'Imagens', 'Textos/Documentos', 'Vídeos', 'Áudios', 'Planilhas', 'Dados georeferenciados', 'Entre as fontes de dados listadas, quais você utiliza na maior parte do tempo?', 'Dados relacionais (estruturados em bancos SQL', 'Dados armazenados em bancos NoSQL', 'Imagens', 'Textos/Documentos', 'Vídeos', 'Áudios', 'Planilhas', 'Dados georeferenciados', 'Quais das linguagens listadas abaixo você utiliza no trabalho?', 'SQL', 'R ', 'Python', 'C/C++/C#', '.NET', 'Java', 'Julia', 'SAS/Stata', 'Visual Basic/VBA', 'Scala', 'Matlab', 'PHP', 'Javascript', 'Não utilizo nenhuma linguagem', 'Entre as linguagens listadas abaixo, qual é a que você mais utiliza no trabalho?', 'Entre as linguagens listadas abaixo, qual é a sua preferida?', 'Quais das opções de Cloud listadas abaixo você utiliza no trabalho?', 'MySQL', 'Oracle', 'SQL SERVER', 'Amazon Aurora ou RDS', 'DynamoDB', 'CoachDB', 'Cassandra', 'MongoDB', 'MariaDB', 'Datomic', 'S3', 'PostgreSQL', 'ElasticSearch', 'DB2', 'Microsoft Access', 'SQLite', 'Sybase', 'Firebase', 'Vertica', 'Redis', 'Neo4J', 'Google BigQuery', 'Google Firestore', 'Amazon Redshift', 'Amazon Athena', 'Snowflake', 'Databricks', 'HBase', 'Presto', 'Splunk', 'SAP HANA', 'Hive', 'Firebird', 'Dentre as opções listadas, qual sua Cloud preferida?', 'Azure (Microsoft', 'Amazon Web Services (AWS', 'Google Cloud (GCP', 'Microsoft PowerBI', 'Microsoft PowerBI', 'Qlik View/Qlik Sense', 'Tableau', 'Metabase', 'Superset', 'Redash', 'MicroStrategy', 'IBM Analytics/Cognos', 'SAP Business Objects', 'Oracle Business Intelligence', 'Amazon QuickSight', 'Salesforce/Einstein Analytics', 'Mode', 'Alteryx', 'Birst', 'Looker', 'Google Data Studio', 'SAS Visual Analytics', 'Grafana', 'TIBCO Spotfire', 'Pentaho', 'Fazemos todas as análises utilizando apenas Excel ou planilhas do google', 'Não utilizo nenhuma ferramenta de BI no trabalho', 'Qual seu objetivo na área de dados?', 'Qual oportunidade você está buscando?', 'Há quanto tempo você busca uma oportunidade na área de dados?', 'Como tem sido a busca por um emprego na área de dados?', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual como engenheiro de dados?', 'Desenvolvo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.', 'Realizo construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc.', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.', 'Atuo na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.', 'Modelo soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.', 'Desenvolvo/cuido da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.', 'Cuido da qualidade dos dados, metadados e dicionário de dados.', 'Nenhuma das opções listadas refletem meu dia a dia.', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Engineer?', 'Scripts Python', 'SQL & Stored Procedures', 'Apache Airflow', 'Luigi', 'AWS Glue', 'Talend', 'Pentaho', 'Alteryx', 'Stitch', 'Fivetran', 'Google Dataflow', 'Oracle Data Integrator', 'IBM DataStage', 'SAP BW ETL', 'SQL Server Integration Services (SSIS', 'SAS Data Integration', 'Qlik Sense', 'Knime', 'Não utilizo ferramentas de ETL', 'Sua organização possui um Data Lake?', 'Qual tecnologia utilizada como plataforma do Data Lake?', 'Sua organização possui um Data Warehouse?', 'Qual tecnologia utilizada como plataforma do Data Warehouse?', 'Quais as ferramentas de gestão de Qualidade de dados, Metadados e catálogo de dados você utiliza no trabalho?', 'great_expectations', 'dbt', 'AWS Deequ', 'Apache Griffin', 'Datafold', 'Amundsen', 'Monte Carlo', 'SODA', 'Big Eye', 'Data Band', 'Anomalo', 'Metaplane', 'Acceldata', 'Em qual das opções abaixo você gasta a maior parte do seu tempo?', 'Desenvolvendo pipelines de dados utilizando linguagens de programação como Python, Scala, Java etc.', 'Realizando construções de ETLs em ferramentas como Pentaho, Talend, Dataflow etc.', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.', 'Atuando na integração de diferentes fontes de dados através de plataformas proprietárias como Stitch Data, Fivetran etc.', 'Modelando soluções de arquitetura de dados, criando componentes de ingestão de dados, transformação e recuperação da informação.', 'Desenvolvendo/cuidando da manutenção de repositórios de dados baseados em streaming de eventos como Data Lakes e Data Lakehouses.', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados como Data Warehouses, Data Marts etc.', 'Cuidando da qualidade dos dados, metadados e dicionário de dados.', 'Nenhuma das opções listadas refletem meu dia a dia.', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com análise de dados?', 'Processo e analiso dados utilizando linguagens de programação como Python, R etc.', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.', 'Crio consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.', 'Utilizo APIs para extrair dados e complementar minhas análises.', 'Realizo experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.', 'Desenvolvo/cuido da manutenção de ETLs utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.', 'Atuo na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.', 'Desenvolvo/cuido da manutenção de planilhas para atender as áreas de negócio.', 'Utilizo ferramentas avançadas de estatística como SAS', 'Nenhuma das opções listadas refletem meu dia a dia.', 'Quais as ferramentas/tecnologias de ETL que você utiliza no trabalho como Data Analyst?', 'Scripts Python', 'SQL & Stored Procedures', 'Apache Airflow', 'Luigi', 'AWS Glue', 'Talend', 'Pentaho', 'Alteryx', 'Stitch', 'Fivetran', 'Google Dataflow', 'Oracle Data Integrator', 'IBM DataStage', 'SAP BW ETL', 'SQL Server Integration Services (SSIS', 'SAS Data Integration', 'Qlik Sense', 'Knime', 'Databricks', 'Não utilizo ferramentas de ETL', 'Sua empresa utiliza alguma das ferramentas listadas para dar mais autonomia em análise de dados para as áreas de negócio?', 'Ferramentas de AutoML como H2O.ai, Data Robot, BigML etc.', '\"\"Point and Click\"\" Analytics como Alteryx, Knime, Rapidminer etc.', 'Product metricts & Insights como Mixpanel, Amplitude, Adobe Analytics.', 'Ferramentas de análise dentro de ferramentas de CRM como Salesforce Einstein Anaytics ou Zendesk dashboards.', 'Minha empresa não utiliza essas ferramentas.', 'Não sei informar.', 'Em qual das opções abaixo você gasta a maior parte do seu tempo de trabalho?', 'Processando e analisando dados utilizando linguagens de programação como Python, R etc.', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik etc.', 'Criando consultas através da linguagem SQL para exportar informações e compartilhar com as áreas de negócio.', 'Utilizando APIs para extrair dados e complementar minhas análises.', 'Realizando experimentos e estudos utilizando metodologias estatísticas como teste de hipótese, modelos de regressão etc.', 'Desenvolvendo/cuidando da manutenção de ETLs utilizando tecnologias como Talend, Pentaho, Airflow, Dataflow etc.', 'Atuando na modelagem dos dados, com o objetivo de criar conjuntos de dados, Data Warehouses, Data Marts etc.', 'Desenvolvendo/cuidando da manutenção de planilhas do Excel ou Google Sheets para atender as áreas de negócio.', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.', 'Nenhuma das opções listadas refletem meu dia a dia.', 'Quais das opções abaixo fazem parte da sua rotina no trabalho atual com ciência de dados?', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.', 'Sou responsável pela coleta e limpeza dos dados que uso para análise e modelagem.', 'Sou responsável por entrar em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.', 'Desenvolvo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).', 'Sou responsável por colocar modelos em produção, criar os pipelines de dados, APIs de consumo e monitoramento.', 'Cuido da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.', 'Realizo construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc', 'Utilizo ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises estatísticas e ajustar modelos.Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.', 'Crio e dou manutenção em ETLs, DAGs e automações de pipelines de dados.', 'Crio e gerencio soluções de Feature Store e cultura de MLOps.', 'Sou responsável por criar e manter a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.', 'Quais as técnicas e métodos listados abaixo você costuma utilizar no trabalho?', 'Utilizo modelos de regressão (linear, logística, GLM', 'Utilizo redes neurais ou modelos baseados em árvore para criar modelos de classificação', 'Desenvolvo sistemas de recomendação (RecSys', 'Utilizo métodos estatísticos Bayesianos para analisar dados', 'Utilizo técnicas de NLP (Natural Language Processing) para análisar dados não-estruturados', 'Utilizo métodos estatísticos clássicos (Testes de hipótese, análise multivariada, sobrevivência, dados longitudinais, inferência estatistica) para analisar dados', 'Utilizo cadeias de Markov ou HMMs para realizar análises de dados', 'Desenvolvo técnicas de Clusterização (K-means, Spectral, DBScan etc', 'Realizo previsões através de modelos de Séries Temporais (Time Series', 'Utilizo modelos de Reinforcement Learning (aprendizado por reforço', 'Utilizo modelos de Machine Learning para detecção de fraude', 'Utilizo métodos de Visão Computacional', 'Utilizo modelos de Detecção de Churn', 'Quais dessas tecnologias fazem parte do seu dia a dia como cientista de dados?', 'Ferramentas de BI (PowerBI, Looker, Tableau, Qlik etc', 'Planilhas (Excel, Google Sheets etc', 'Ambientes de desenvolvimento local (R-studio, JupyterLab, Anaconda', 'Ambientes de desenvolvimento na nuvem (Google Colab, AWS Sagemaker, Kaggle Notebooks etc', 'Ferramentas de AutoML (Datarobot, H2O, Auto-Keras etc', 'Ferramentas de ETL (Apache Airflow, NiFi, Stitch, Fivetran, Pentaho etc', 'Plataformas de Machine Learning (TensorFlow, Azure Machine Learning, Kubeflow etc', 'Feature Store (Feast, Hopsworks, AWS Feature Store, Databricks Feature Store etc', 'Sistemas de controle de versão (Github, DVC, Neptune, Gitlab etc', 'Plataformas de Data Apps (Streamlit, Shiny, Plotly Dash etc', 'Ferramentas de estatística avançada como SPSS, SAS, etc.', 'Em qual das opções abaixo você gasta a maior parte do seu tempo no trabalho?', 'Estudos Ad-hoc com o objetivo de confirmar hipóteses, realizar modelos preditivos, forecasts, análise de cluster para resolver problemas pontuais e responder perguntas das áreas de negócio.', 'Coletando e limpando os dados que uso para análise e modelagem.', 'Entrando em contato com os times de negócio para definição do problema, identificar a solução e apresentação de resultados.', 'Desenvolvendo modelos de Machine Learning com o objetivo de colocar em produção em sistemas (produtos de dados).', 'Colocando modelos em produção, criando os pipelines de dados, APIs de consumo e monitoramento.', 'Cuidando da manutenção de modelos de Machine Learning já em produção, atuando no monitoramento, ajustes e refatoração quando necessário.', 'Realizando construções de dashboards em ferramentas de BI como PowerBI, Tableau, Looker, Qlik, etc.', 'Utilizando ferramentas avançadas de estatística como SAS, SPSS, Stata etc, para realizar análises.', 'Criando e dando manutenção em ETLs, DAGs e automações de pipelines de dados.', 'Criando e gerenciando soluções de Feature Store e cultura de MLOps.', 'Criando e mantendo a infra que meus modelos e soluções rodam (clusters, servidores, API, containers, etc.'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "responsible-ai-datahackers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
